{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ea99faf28>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    normalize_val = x/255.\n",
    "    return normalize_val\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    return np.eye(10, dtype=float)[x]\n",
    "    #return None\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, image_shape[0],image_shape[1], image_shape[2]], name='x')\n",
    "    \n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name = 'y')\n",
    "    \n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name= 'keep_prob')\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    W = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1] ,x_tensor.get_shape().as_list()[3] ,conv_num_outputs], mean=0.0,stddev=0.05, dtype = tf.float32))\n",
    "    b = tf.Variable(tf.zeros([conv_num_outputs], dtype = tf.float32))\n",
    "    x = tf.nn.conv2d(x_tensor, W, strides=[1,conv_strides[0] , conv_strides[1] ,1],padding='SAME' )\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    conv1 = tf.nn.relu(x)\n",
    "    return tf.nn.max_pool(conv1,ksize=[1,pool_ksize[0] ,pool_ksize[1] ,1], strides=[1,pool_strides[0] , pool_strides[1] ,1], padding='SAME')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    batch_size = x_tensor.get_shape().as_list()[0]\n",
    "    \n",
    "    width = x_tensor.get_shape().as_list()[1]\n",
    "    height = x_tensor.get_shape().as_list()[2]\n",
    "    depth = x_tensor.get_shape().as_list()[3]\n",
    "    flatten_image_size = width*height*depth\n",
    "    return tf.reshape(x_tensor,[-1, flatten_image_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    wfc = tf.Variable(tf.truncated_normal([x_tensor.get_shape().as_list()[1], num_outputs]))\n",
    "    bfc = tf.Variable(tf.truncated_normal([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, wfc), bfc)\n",
    "    out = tf.nn.relu(x_tensor)\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.random_normal([x_tensor.get_shape().as_list()[1], num_outputs]))\n",
    "    bias = tf.Variable(tf.random_normal([num_outputs]))\n",
    "    \n",
    "    return tf.add(tf.matmul(x_tensor, weights), bias)\n",
    "    \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    x_tensor = x\n",
    "    x_tensor = conv2d_maxpool(x_tensor,\\\n",
    "                   conv_num_outputs = 32,\\\n",
    "                   conv_ksize = (3,3),\\\n",
    "                   conv_strides = (1,1),\\\n",
    "                   pool_ksize = (3,3),\\\n",
    "                   pool_strides = (1,1))\n",
    "    '''x_tensor = conv2d_maxpool(x_tensor,\\\n",
    "                   conv_num_outputs = 64,\\\n",
    "                   conv_ksize = (3,3),\\\n",
    "                   conv_strides = (1,1),\\\n",
    "                   pool_ksize = (3,3),\\\n",
    "                   pool_strides = (1,1))\n",
    "    \n",
    "    x_tensor = conv2d_maxpool(x_tensor,\\\n",
    "                   conv_num_outputs = 128,\\\n",
    "                   conv_ksize = (5,5),\\\n",
    "                   conv_strides = (1,1),\\\n",
    "                   pool_ksize = (3,3),\\\n",
    "                   pool_strides = (1,1))\n",
    "    '''\n",
    "    x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    x_tensor = flatten(x_tensor)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    x_tensor = fully_conn(x_tensor, num_outputs=128)\n",
    "    #x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    #x_tensor = fully_conn(x_tensor, num_outputs=64)\n",
    "    #x_tensor = tf.nn.dropout(x_tensor, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    out = output(x_tensor, num_outputs= 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,\\\n",
    "                feed_dict={x: feature_batch,\\\n",
    "                           y: label_batch,\\\n",
    "                           keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    print(\"\")\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})    \n",
    "    \n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})    \n",
    "    print (\"loss: \", loss, \"valid_acc \", valid_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "loss:  6.11306 valid_acc  0.136\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "loss:  3.72891 valid_acc  0.135\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "loss:  2.57391 valid_acc  0.1388\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "loss:  2.29164 valid_acc  0.147\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "loss:  2.20588 valid_acc  0.1558\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "loss:  2.09557 valid_acc  0.1674\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "loss:  2.12202 valid_acc  0.1584\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "loss:  2.14592 valid_acc  0.1598\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "loss:  2.17938 valid_acc  0.1546\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "loss:  2.15289 valid_acc  0.1692\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "loss:  2.04849 valid_acc  0.182\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "loss:  2.12548 valid_acc  0.1758\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "loss:  2.08238 valid_acc  0.1852\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "loss:  2.08759 valid_acc  0.1842\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "loss:  2.09572 valid_acc  0.1944\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "loss:  2.04563 valid_acc  0.196\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "loss:  2.02186 valid_acc  0.2078\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "loss:  2.0704 valid_acc  0.1998\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "loss:  2.05524 valid_acc  0.199\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "loss:  2.07424 valid_acc  0.1974\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "loss:  2.02431 valid_acc  0.219\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "loss:  2.00198 valid_acc  0.211\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "loss:  2.00229 valid_acc  0.2186\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "loss:  1.96486 valid_acc  0.2158\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "loss:  1.94108 valid_acc  0.2422\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "loss:  1.91663 valid_acc  0.2378\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "loss:  1.89788 valid_acc  0.245\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "loss:  1.87092 valid_acc  0.2504\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "loss:  1.90019 valid_acc  0.2608\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "loss:  1.84221 valid_acc  0.2564\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "loss:  1.89378 valid_acc  0.2284\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "loss:  1.87046 valid_acc  0.2854\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "loss:  1.81923 valid_acc  0.2696\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "loss:  1.84909 valid_acc  0.2484\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "loss:  1.80607 valid_acc  0.2772\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "loss:  1.80752 valid_acc  0.2746\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "loss:  1.80419 valid_acc  0.2718\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "loss:  1.84352 valid_acc  0.2436\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "loss:  1.87911 valid_acc  0.2672\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "loss:  1.78256 valid_acc  0.2906\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "loss:  1.7726 valid_acc  0.3086\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "loss:  1.7627 valid_acc  0.2952\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "loss:  1.73306 valid_acc  0.3098\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "loss:  1.85877 valid_acc  0.2766\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "loss:  1.71765 valid_acc  0.3128\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "loss:  1.70562 valid_acc  0.307\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "loss:  1.71565 valid_acc  0.3156\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "loss:  1.74361 valid_acc  0.3226\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "loss:  1.6535 valid_acc  0.3312\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "loss:  1.68207 valid_acc  0.3254\n",
      "Epoch 51, CIFAR-10 Batch 1:  \n",
      "loss:  1.73815 valid_acc  0.2916\n",
      "Epoch 52, CIFAR-10 Batch 1:  \n",
      "loss:  1.62477 valid_acc  0.331\n",
      "Epoch 53, CIFAR-10 Batch 1:  \n",
      "loss:  1.6818 valid_acc  0.3186\n",
      "Epoch 54, CIFAR-10 Batch 1:  \n",
      "loss:  1.63274 valid_acc  0.3366\n",
      "Epoch 55, CIFAR-10 Batch 1:  \n",
      "loss:  1.66024 valid_acc  0.3306\n",
      "Epoch 56, CIFAR-10 Batch 1:  \n",
      "loss:  1.59232 valid_acc  0.3452\n",
      "Epoch 57, CIFAR-10 Batch 1:  \n",
      "loss:  1.67162 valid_acc  0.3186\n",
      "Epoch 58, CIFAR-10 Batch 1:  \n",
      "loss:  1.659 valid_acc  0.3172\n",
      "Epoch 59, CIFAR-10 Batch 1:  \n",
      "loss:  1.62837 valid_acc  0.3414\n",
      "Epoch 60, CIFAR-10 Batch 1:  \n",
      "loss:  1.50607 valid_acc  0.34\n",
      "Epoch 61, CIFAR-10 Batch 1:  \n",
      "loss:  1.55171 valid_acc  0.3426\n",
      "Epoch 62, CIFAR-10 Batch 1:  \n",
      "loss:  1.53558 valid_acc  0.3376\n",
      "Epoch 63, CIFAR-10 Batch 1:  \n",
      "loss:  1.53892 valid_acc  0.3544\n",
      "Epoch 64, CIFAR-10 Batch 1:  \n",
      "loss:  1.50397 valid_acc  0.3474\n",
      "Epoch 65, CIFAR-10 Batch 1:  \n",
      "loss:  1.49529 valid_acc  0.3504\n",
      "Epoch 66, CIFAR-10 Batch 1:  \n",
      "loss:  1.55461 valid_acc  0.333\n",
      "Epoch 67, CIFAR-10 Batch 1:  \n",
      "loss:  1.53611 valid_acc  0.3452\n",
      "Epoch 68, CIFAR-10 Batch 1:  \n",
      "loss:  1.4848 valid_acc  0.343\n",
      "Epoch 69, CIFAR-10 Batch 1:  \n",
      "loss:  1.45734 valid_acc  0.3582\n",
      "Epoch 70, CIFAR-10 Batch 1:  \n",
      "loss:  1.59145 valid_acc  0.3248\n",
      "Epoch 71, CIFAR-10 Batch 1:  \n",
      "loss:  1.4812 valid_acc  0.3506\n",
      "Epoch 72, CIFAR-10 Batch 1:  \n",
      "loss:  1.42492 valid_acc  0.3624\n",
      "Epoch 73, CIFAR-10 Batch 1:  \n",
      "loss:  1.39735 valid_acc  0.3622\n",
      "Epoch 74, CIFAR-10 Batch 1:  \n",
      "loss:  1.38517 valid_acc  0.3598\n",
      "Epoch 75, CIFAR-10 Batch 1:  \n",
      "loss:  1.41604 valid_acc  0.361\n",
      "Epoch 76, CIFAR-10 Batch 1:  \n",
      "loss:  1.40994 valid_acc  0.3622\n",
      "Epoch 77, CIFAR-10 Batch 1:  \n",
      "loss:  1.45101 valid_acc  0.3494\n",
      "Epoch 78, CIFAR-10 Batch 1:  \n",
      "loss:  1.39617 valid_acc  0.3572\n",
      "Epoch 79, CIFAR-10 Batch 1:  \n",
      "loss:  1.34739 valid_acc  0.3646\n",
      "Epoch 80, CIFAR-10 Batch 1:  \n",
      "loss:  1.44587 valid_acc  0.3426\n",
      "Epoch 81, CIFAR-10 Batch 1:  \n",
      "loss:  1.31386 valid_acc  0.3538\n",
      "Epoch 82, CIFAR-10 Batch 1:  \n",
      "loss:  1.34473 valid_acc  0.3644\n",
      "Epoch 83, CIFAR-10 Batch 1:  \n",
      "loss:  1.36756 valid_acc  0.3566\n",
      "Epoch 84, CIFAR-10 Batch 1:  \n",
      "loss:  1.37669 valid_acc  0.3506\n",
      "Epoch 85, CIFAR-10 Batch 1:  \n",
      "loss:  1.31482 valid_acc  0.3686\n",
      "Epoch 86, CIFAR-10 Batch 1:  \n",
      "loss:  1.28027 valid_acc  0.3658\n",
      "Epoch 87, CIFAR-10 Batch 1:  \n",
      "loss:  1.28132 valid_acc  0.3654\n",
      "Epoch 88, CIFAR-10 Batch 1:  \n",
      "loss:  1.32634 valid_acc  0.3576\n",
      "Epoch 89, CIFAR-10 Batch 1:  \n",
      "loss:  1.30328 valid_acc  0.3582\n",
      "Epoch 90, CIFAR-10 Batch 1:  \n",
      "loss:  1.27584 valid_acc  0.3774\n",
      "Epoch 91, CIFAR-10 Batch 1:  \n",
      "loss:  1.25109 valid_acc  0.3722\n",
      "Epoch 92, CIFAR-10 Batch 1:  \n",
      "loss:  1.43854 valid_acc  0.3382\n",
      "Epoch 93, CIFAR-10 Batch 1:  \n",
      "loss:  1.30509 valid_acc  0.3566\n",
      "Epoch 94, CIFAR-10 Batch 1:  \n",
      "loss:  1.24604 valid_acc  0.3578\n",
      "Epoch 95, CIFAR-10 Batch 1:  \n",
      "loss:  1.21366 valid_acc  0.365\n",
      "Epoch 96, CIFAR-10 Batch 1:  \n",
      "loss:  1.21732 valid_acc  0.3544\n",
      "Epoch 97, CIFAR-10 Batch 1:  \n",
      "loss:  1.31616 valid_acc  0.3526\n",
      "Epoch 98, CIFAR-10 Batch 1:  \n",
      "loss:  1.24358 valid_acc  0.361\n",
      "Epoch 99, CIFAR-10 Batch 1:  \n",
      "loss:  1.25939 valid_acc  0.3544\n",
      "Epoch 100, CIFAR-10 Batch 1:  \n",
      "loss:  1.19536 valid_acc  0.366\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "loss:  6.28248 valid_acc  0.116\n",
      "Epoch  1, CIFAR-10 Batch 2:  \n",
      "loss:  3.0536 valid_acc  0.113\n",
      "Epoch  1, CIFAR-10 Batch 3:  \n",
      "loss:  2.74001 valid_acc  0.1192\n",
      "Epoch  1, CIFAR-10 Batch 4:  \n",
      "loss:  2.15045 valid_acc  0.1624\n",
      "Epoch  1, CIFAR-10 Batch 5:  \n",
      "loss:  2.45633 valid_acc  0.1342\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "loss:  2.42896 valid_acc  0.1538\n",
      "Epoch  2, CIFAR-10 Batch 2:  \n",
      "loss:  2.2956 valid_acc  0.1584\n",
      "Epoch  2, CIFAR-10 Batch 3:  \n",
      "loss:  2.20909 valid_acc  0.1658\n",
      "Epoch  2, CIFAR-10 Batch 4:  \n",
      "loss:  2.14805 valid_acc  0.1604\n",
      "Epoch  2, CIFAR-10 Batch 5:  \n",
      "loss:  2.27148 valid_acc  0.1626\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "loss:  2.24033 valid_acc  0.1934\n",
      "Epoch  3, CIFAR-10 Batch 2:  \n",
      "loss:  2.24525 valid_acc  0.178\n",
      "Epoch  3, CIFAR-10 Batch 3:  \n",
      "loss:  2.11495 valid_acc  0.1898\n",
      "Epoch  3, CIFAR-10 Batch 4:  \n",
      "loss:  2.0338 valid_acc  0.2016\n",
      "Epoch  3, CIFAR-10 Batch 5:  \n",
      "loss:  2.20412 valid_acc  0.2002\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "loss:  2.19203 valid_acc  0.213\n",
      "Epoch  4, CIFAR-10 Batch 2:  \n",
      "loss:  2.11606 valid_acc  0.2222\n",
      "Epoch  4, CIFAR-10 Batch 3:  \n",
      "loss:  1.97232 valid_acc  0.2476\n",
      "Epoch  4, CIFAR-10 Batch 4:  \n",
      "loss:  2.08932 valid_acc  0.1808\n",
      "Epoch  4, CIFAR-10 Batch 5:  \n",
      "loss:  2.10861 valid_acc  0.2228\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "loss:  2.14549 valid_acc  0.235\n",
      "Epoch  5, CIFAR-10 Batch 2:  \n",
      "loss:  2.1169 valid_acc  0.2202\n",
      "Epoch  5, CIFAR-10 Batch 3:  \n",
      "loss:  2.02878 valid_acc  0.2248\n",
      "Epoch  5, CIFAR-10 Batch 4:  \n",
      "loss:  1.96389 valid_acc  0.2364\n",
      "Epoch  5, CIFAR-10 Batch 5:  \n",
      "loss:  2.10542 valid_acc  0.237\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "loss:  2.02968 valid_acc  0.2644\n",
      "Epoch  6, CIFAR-10 Batch 2:  \n",
      "loss:  2.01416 valid_acc  0.2464\n",
      "Epoch  6, CIFAR-10 Batch 3:  \n",
      "loss:  1.87918 valid_acc  0.2852\n",
      "Epoch  6, CIFAR-10 Batch 4:  \n",
      "loss:  1.84856 valid_acc  0.2694\n",
      "Epoch  6, CIFAR-10 Batch 5:  \n",
      "loss:  2.03495 valid_acc  0.2934\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "loss:  2.06991 valid_acc  0.2666\n",
      "Epoch  7, CIFAR-10 Batch 2:  \n",
      "loss:  1.8976 valid_acc  0.3238\n",
      "Epoch  7, CIFAR-10 Batch 3:  \n",
      "loss:  1.68117 valid_acc  0.2894\n",
      "Epoch  7, CIFAR-10 Batch 4:  \n",
      "loss:  1.84175 valid_acc  0.2864\n",
      "Epoch  7, CIFAR-10 Batch 5:  \n",
      "loss:  1.97303 valid_acc  0.3086\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "loss:  1.99392 valid_acc  0.3148\n",
      "Epoch  8, CIFAR-10 Batch 2:  \n",
      "loss:  1.90423 valid_acc  0.3396\n",
      "Epoch  8, CIFAR-10 Batch 3:  \n",
      "loss:  1.87373 valid_acc  0.2846\n",
      "Epoch  8, CIFAR-10 Batch 4:  \n",
      "loss:  1.66722 valid_acc  0.3302\n",
      "Epoch  8, CIFAR-10 Batch 5:  \n",
      "loss:  1.84524 valid_acc  0.3368\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "loss:  2.00651 valid_acc  0.3374\n",
      "Epoch  9, CIFAR-10 Batch 2:  \n",
      "loss:  1.86849 valid_acc  0.3484\n",
      "Epoch  9, CIFAR-10 Batch 3:  \n",
      "loss:  1.67062 valid_acc  0.3438\n",
      "Epoch  9, CIFAR-10 Batch 4:  \n",
      "loss:  1.6583 valid_acc  0.3578\n",
      "Epoch  9, CIFAR-10 Batch 5:  \n",
      "loss:  1.79829 valid_acc  0.3554\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "loss:  1.99015 valid_acc  0.3596\n",
      "Epoch 10, CIFAR-10 Batch 2:  \n",
      "loss:  1.88839 valid_acc  0.3694\n",
      "Epoch 10, CIFAR-10 Batch 3:  \n",
      "loss:  1.63288 valid_acc  0.3542\n",
      "Epoch 10, CIFAR-10 Batch 4:  \n",
      "loss:  1.63635 valid_acc  0.3648\n",
      "Epoch 10, CIFAR-10 Batch 5:  \n",
      "loss:  1.74302 valid_acc  0.369\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "loss:  1.9668 valid_acc  0.3332\n",
      "Epoch 11, CIFAR-10 Batch 2:  \n",
      "loss:  1.82968 valid_acc  0.3266\n",
      "Epoch 11, CIFAR-10 Batch 3:  \n",
      "loss:  1.54491 valid_acc  0.3588\n",
      "Epoch 11, CIFAR-10 Batch 4:  \n",
      "loss:  1.62202 valid_acc  0.37\n",
      "Epoch 11, CIFAR-10 Batch 5:  \n",
      "loss:  1.8097 valid_acc  0.3508\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "loss:  1.965 valid_acc  0.3258\n",
      "Epoch 12, CIFAR-10 Batch 2:  \n",
      "loss:  1.79501 valid_acc  0.3396\n",
      "Epoch 12, CIFAR-10 Batch 3:  \n",
      "loss:  1.69889 valid_acc  0.3462\n",
      "Epoch 12, CIFAR-10 Batch 4:  \n",
      "loss:  1.60431 valid_acc  0.3726\n",
      "Epoch 12, CIFAR-10 Batch 5:  \n",
      "loss:  1.7489 valid_acc  0.3634\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "loss:  1.93288 valid_acc  0.3628\n",
      "Epoch 13, CIFAR-10 Batch 2:  \n",
      "loss:  1.85882 valid_acc  0.3638\n",
      "Epoch 13, CIFAR-10 Batch 3:  \n",
      "loss:  1.5833 valid_acc  0.357\n",
      "Epoch 13, CIFAR-10 Batch 4:  \n",
      "loss:  1.62751 valid_acc  0.3752\n",
      "Epoch 13, CIFAR-10 Batch 5:  \n",
      "loss:  1.68719 valid_acc  0.3806\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "loss:  1.89848 valid_acc  0.3738\n",
      "Epoch 14, CIFAR-10 Batch 2:  \n",
      "loss:  1.78147 valid_acc  0.3824\n",
      "Epoch 14, CIFAR-10 Batch 3:  \n",
      "loss:  1.52281 valid_acc  0.3674\n",
      "Epoch 14, CIFAR-10 Batch 4:  \n",
      "loss:  1.58791 valid_acc  0.375\n",
      "Epoch 14, CIFAR-10 Batch 5:  \n",
      "loss:  1.67889 valid_acc  0.37\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "loss:  1.95625 valid_acc  0.3148\n",
      "Epoch 15, CIFAR-10 Batch 2:  \n",
      "loss:  1.83743 valid_acc  0.3774\n",
      "Epoch 15, CIFAR-10 Batch 3:  \n",
      "loss:  1.47445 valid_acc  0.3458\n",
      "Epoch 15, CIFAR-10 Batch 4:  \n",
      "loss:  1.58423 valid_acc  0.3782\n",
      "Epoch 15, CIFAR-10 Batch 5:  \n",
      "loss:  1.67531 valid_acc  0.3734\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "loss:  1.86262 valid_acc  0.3688\n",
      "Epoch 16, CIFAR-10 Batch 2:  \n",
      "loss:  1.70301 valid_acc  0.3762\n",
      "Epoch 16, CIFAR-10 Batch 3:  \n",
      "loss:  1.51398 valid_acc  0.3706\n",
      "Epoch 16, CIFAR-10 Batch 4:  \n",
      "loss:  1.52908 valid_acc  0.385\n",
      "Epoch 16, CIFAR-10 Batch 5:  \n",
      "loss:  1.57653 valid_acc  0.3848\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "loss:  1.88854 valid_acc  0.3564\n",
      "Epoch 17, CIFAR-10 Batch 2:  \n",
      "loss:  1.71563 valid_acc  0.3874\n",
      "Epoch 17, CIFAR-10 Batch 3:  \n",
      "loss:  1.54551 valid_acc  0.3472\n",
      "Epoch 17, CIFAR-10 Batch 4:  \n",
      "loss:  1.57541 valid_acc  0.3894\n",
      "Epoch 17, CIFAR-10 Batch 5:  \n",
      "loss:  1.65343 valid_acc  0.3728\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "loss:  1.85271 valid_acc  0.3464\n",
      "Epoch 18, CIFAR-10 Batch 2:  \n",
      "loss:  1.73533 valid_acc  0.375\n",
      "Epoch 18, CIFAR-10 Batch 3:  \n",
      "loss:  1.45652 valid_acc  0.3688\n",
      "Epoch 18, CIFAR-10 Batch 4:  \n",
      "loss:  1.52648 valid_acc  0.3944\n",
      "Epoch 18, CIFAR-10 Batch 5:  \n",
      "loss:  1.60554 valid_acc  0.3892\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "loss:  1.81158 valid_acc  0.3834\n",
      "Epoch 19, CIFAR-10 Batch 2:  \n",
      "loss:  1.6986 valid_acc  0.3796\n",
      "Epoch 19, CIFAR-10 Batch 3:  \n",
      "loss:  1.46459 valid_acc  0.3766\n",
      "Epoch 19, CIFAR-10 Batch 4:  \n",
      "loss:  1.50262 valid_acc  0.39\n",
      "Epoch 19, CIFAR-10 Batch 5:  \n",
      "loss:  1.56953 valid_acc  0.3852\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "loss:  1.84561 valid_acc  0.3812\n",
      "Epoch 20, CIFAR-10 Batch 2:  \n",
      "loss:  1.68816 valid_acc  0.389\n",
      "Epoch 20, CIFAR-10 Batch 3:  \n",
      "loss:  1.425 valid_acc  0.3822\n",
      "Epoch 20, CIFAR-10 Batch 4:  \n",
      "loss:  1.48436 valid_acc  0.3902\n",
      "Epoch 20, CIFAR-10 Batch 5:  \n",
      "loss:  1.52409 valid_acc  0.3936\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "loss:  1.81915 valid_acc  0.39\n",
      "Epoch 21, CIFAR-10 Batch 2:  \n",
      "loss:  1.64378 valid_acc  0.3934\n",
      "Epoch 21, CIFAR-10 Batch 3:  \n",
      "loss:  1.4258 valid_acc  0.3678\n",
      "Epoch 21, CIFAR-10 Batch 4:  \n",
      "loss:  1.50361 valid_acc  0.383\n",
      "Epoch 21, CIFAR-10 Batch 5:  \n",
      "loss:  1.58183 valid_acc  0.3854\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "loss:  1.76449 valid_acc  0.398\n",
      "Epoch 22, CIFAR-10 Batch 2:  \n",
      "loss:  1.64903 valid_acc  0.3958\n",
      "Epoch 22, CIFAR-10 Batch 3:  \n",
      "loss:  1.40384 valid_acc  0.3808\n",
      "Epoch 22, CIFAR-10 Batch 4:  \n",
      "loss:  1.46514 valid_acc  0.3958\n",
      "Epoch 22, CIFAR-10 Batch 5:  \n",
      "loss:  1.52464 valid_acc  0.3898\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "loss:  1.7786 valid_acc  0.3832\n",
      "Epoch 23, CIFAR-10 Batch 2:  \n",
      "loss:  1.58393 valid_acc  0.4026\n",
      "Epoch 23, CIFAR-10 Batch 3:  \n",
      "loss:  1.38337 valid_acc  0.3818\n",
      "Epoch 23, CIFAR-10 Batch 4:  \n",
      "loss:  1.51113 valid_acc  0.3878\n",
      "Epoch 23, CIFAR-10 Batch 5:  \n",
      "loss:  1.53519 valid_acc  0.3908\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "loss:  1.80337 valid_acc  0.3562\n",
      "Epoch 24, CIFAR-10 Batch 2:  \n",
      "loss:  1.61909 valid_acc  0.3954\n",
      "Epoch 24, CIFAR-10 Batch 3:  \n",
      "loss:  1.38927 valid_acc  0.39\n",
      "Epoch 24, CIFAR-10 Batch 4:  \n",
      "loss:  1.48638 valid_acc  0.4028\n",
      "Epoch 24, CIFAR-10 Batch 5:  \n",
      "loss:  1.49091 valid_acc  0.3854\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "loss:  1.74411 valid_acc  0.3766\n",
      "Epoch 25, CIFAR-10 Batch 2:  \n",
      "loss:  1.59069 valid_acc  0.394\n",
      "Epoch 25, CIFAR-10 Batch 3:  \n",
      "loss:  1.36462 valid_acc  0.3782\n",
      "Epoch 25, CIFAR-10 Batch 4:  \n",
      "loss:  1.42528 valid_acc  0.4036\n",
      "Epoch 25, CIFAR-10 Batch 5:  \n",
      "loss:  1.49752 valid_acc  0.3942\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "loss:  1.76331 valid_acc  0.3622\n",
      "Epoch 26, CIFAR-10 Batch 2:  \n",
      "loss:  1.61755 valid_acc  0.3954\n",
      "Epoch 26, CIFAR-10 Batch 3:  \n",
      "loss:  1.37509 valid_acc  0.3886\n",
      "Epoch 26, CIFAR-10 Batch 4:  \n",
      "loss:  1.40431 valid_acc  0.4012\n",
      "Epoch 26, CIFAR-10 Batch 5:  \n",
      "loss:  1.48988 valid_acc  0.3966\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "loss:  1.73865 valid_acc  0.3856\n",
      "Epoch 27, CIFAR-10 Batch 2:  \n",
      "loss:  1.61999 valid_acc  0.3902\n",
      "Epoch 27, CIFAR-10 Batch 3:  \n",
      "loss:  1.36876 valid_acc  0.3856\n",
      "Epoch 27, CIFAR-10 Batch 4:  \n",
      "loss:  1.43006 valid_acc  0.4024\n",
      "Epoch 27, CIFAR-10 Batch 5:  \n",
      "loss:  1.53791 valid_acc  0.381\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "loss:  1.68034 valid_acc  0.3984\n",
      "Epoch 28, CIFAR-10 Batch 2:  \n",
      "loss:  1.49327 valid_acc  0.4026\n",
      "Epoch 28, CIFAR-10 Batch 3:  \n",
      "loss:  1.34244 valid_acc  0.398\n",
      "Epoch 28, CIFAR-10 Batch 4:  \n",
      "loss:  1.39756 valid_acc  0.4076\n",
      "Epoch 28, CIFAR-10 Batch 5:  \n",
      "loss:  1.4585 valid_acc  0.3964\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "loss:  1.63207 valid_acc  0.4058\n",
      "Epoch 29, CIFAR-10 Batch 2:  \n",
      "loss:  1.46604 valid_acc  0.4056\n",
      "Epoch 29, CIFAR-10 Batch 3:  \n",
      "loss:  1.33712 valid_acc  0.3946\n",
      "Epoch 29, CIFAR-10 Batch 4:  \n",
      "loss:  1.41906 valid_acc  0.4116\n",
      "Epoch 29, CIFAR-10 Batch 5:  \n",
      "loss:  1.43773 valid_acc  0.4048\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "loss:  1.61038 valid_acc  0.4032\n",
      "Epoch 30, CIFAR-10 Batch 2:  \n",
      "loss:  1.65162 valid_acc  0.3556\n",
      "Epoch 30, CIFAR-10 Batch 3:  \n",
      "loss:  1.37836 valid_acc  0.3884\n",
      "Epoch 30, CIFAR-10 Batch 4:  \n",
      "loss:  1.37308 valid_acc  0.4104\n",
      "Epoch 30, CIFAR-10 Batch 5:  \n",
      "loss:  1.47235 valid_acc  0.3938\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "loss:  1.57509 valid_acc  0.4062\n",
      "Epoch 31, CIFAR-10 Batch 2:  \n",
      "loss:  1.52036 valid_acc  0.3934\n",
      "Epoch 31, CIFAR-10 Batch 3:  \n",
      "loss:  1.29756 valid_acc  0.3984\n",
      "Epoch 31, CIFAR-10 Batch 4:  \n",
      "loss:  1.41692 valid_acc  0.4004\n",
      "Epoch 31, CIFAR-10 Batch 5:  \n",
      "loss:  1.42654 valid_acc  0.3996\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "loss:  1.60567 valid_acc  0.4178\n",
      "Epoch 32, CIFAR-10 Batch 2:  \n",
      "loss:  1.44971 valid_acc  0.4094\n",
      "Epoch 32, CIFAR-10 Batch 3:  \n",
      "loss:  1.30548 valid_acc  0.4002\n",
      "Epoch 32, CIFAR-10 Batch 4:  \n",
      "loss:  1.3757 valid_acc  0.4118\n",
      "Epoch 32, CIFAR-10 Batch 5:  \n",
      "loss:  1.39988 valid_acc  0.404\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "loss:  1.59432 valid_acc  0.3964\n",
      "Epoch 33, CIFAR-10 Batch 2:  \n",
      "loss:  1.50599 valid_acc  0.3966\n",
      "Epoch 33, CIFAR-10 Batch 3:  \n",
      "loss:  1.30616 valid_acc  0.3984\n",
      "Epoch 33, CIFAR-10 Batch 4:  \n",
      "loss:  1.39039 valid_acc  0.403\n",
      "Epoch 33, CIFAR-10 Batch 5:  \n",
      "loss:  1.38231 valid_acc  0.3936\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "loss:  1.64025 valid_acc  0.4044\n",
      "Epoch 34, CIFAR-10 Batch 2:  \n",
      "loss:  1.40452 valid_acc  0.4158\n",
      "Epoch 34, CIFAR-10 Batch 3:  \n",
      "loss:  1.29697 valid_acc  0.3944\n",
      "Epoch 34, CIFAR-10 Batch 4:  \n",
      "loss:  1.37908 valid_acc  0.4124\n",
      "Epoch 34, CIFAR-10 Batch 5:  \n",
      "loss:  1.41984 valid_acc  0.4002\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "loss:  1.57731 valid_acc  0.4164\n",
      "Epoch 35, CIFAR-10 Batch 2:  \n",
      "loss:  1.46801 valid_acc  0.3986\n",
      "Epoch 35, CIFAR-10 Batch 3:  \n",
      "loss:  1.29502 valid_acc  0.3916\n",
      "Epoch 35, CIFAR-10 Batch 4:  \n",
      "loss:  1.3168 valid_acc  0.4186\n",
      "Epoch 35, CIFAR-10 Batch 5:  \n",
      "loss:  1.35772 valid_acc  0.4068\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "loss:  1.64816 valid_acc  0.4124\n",
      "Epoch 36, CIFAR-10 Batch 2:  \n",
      "loss:  1.3878 valid_acc  0.4078\n",
      "Epoch 36, CIFAR-10 Batch 3:  \n",
      "loss:  1.26846 valid_acc  0.4066\n",
      "Epoch 36, CIFAR-10 Batch 4:  \n",
      "loss:  1.34436 valid_acc  0.412\n",
      "Epoch 36, CIFAR-10 Batch 5:  \n",
      "loss:  1.35983 valid_acc  0.392\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "loss:  1.59442 valid_acc  0.4078\n",
      "Epoch 37, CIFAR-10 Batch 2:  \n",
      "loss:  1.36346 valid_acc  0.4102\n",
      "Epoch 37, CIFAR-10 Batch 3:  \n",
      "loss:  1.26657 valid_acc  0.3978\n",
      "Epoch 37, CIFAR-10 Batch 4:  \n",
      "loss:  1.32209 valid_acc  0.4204\n",
      "Epoch 37, CIFAR-10 Batch 5:  \n",
      "loss:  1.43151 valid_acc  0.3892\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "loss:  1.5268 valid_acc  0.417\n",
      "Epoch 38, CIFAR-10 Batch 2:  \n",
      "loss:  1.49149 valid_acc  0.384\n",
      "Epoch 38, CIFAR-10 Batch 3:  \n",
      "loss:  1.28186 valid_acc  0.3874\n",
      "Epoch 38, CIFAR-10 Batch 4:  \n",
      "loss:  1.3841 valid_acc  0.3936\n",
      "Epoch 38, CIFAR-10 Batch 5:  \n",
      "loss:  1.31768 valid_acc  0.4152\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "loss:  1.488 valid_acc  0.4198\n",
      "Epoch 39, CIFAR-10 Batch 2:  \n",
      "loss:  1.44146 valid_acc  0.4078\n",
      "Epoch 39, CIFAR-10 Batch 3:  \n",
      "loss:  1.28845 valid_acc  0.3938\n",
      "Epoch 39, CIFAR-10 Batch 4:  \n",
      "loss:  1.28905 valid_acc  0.4218\n",
      "Epoch 39, CIFAR-10 Batch 5:  \n",
      "loss:  1.44763 valid_acc  0.379\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "loss:  1.50272 valid_acc  0.4168\n",
      "Epoch 40, CIFAR-10 Batch 2:  \n",
      "loss:  1.32987 valid_acc  0.4174\n",
      "Epoch 40, CIFAR-10 Batch 3:  \n",
      "loss:  1.25853 valid_acc  0.4138\n",
      "Epoch 40, CIFAR-10 Batch 4:  \n",
      "loss:  1.33713 valid_acc  0.3958\n",
      "Epoch 40, CIFAR-10 Batch 5:  \n",
      "loss:  1.30843 valid_acc  0.4122\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "loss:  1.48167 valid_acc  0.4198\n",
      "Epoch 41, CIFAR-10 Batch 2:  \n",
      "loss:  1.41631 valid_acc  0.3994\n",
      "Epoch 41, CIFAR-10 Batch 3:  \n",
      "loss:  1.24321 valid_acc  0.41\n",
      "Epoch 41, CIFAR-10 Batch 4:  \n",
      "loss:  1.28343 valid_acc  0.4216\n",
      "Epoch 41, CIFAR-10 Batch 5:  \n",
      "loss:  1.32521 valid_acc  0.4092\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "loss:  1.46475 valid_acc  0.414\n",
      "Epoch 42, CIFAR-10 Batch 2:  \n",
      "loss:  1.30789 valid_acc  0.4166\n",
      "Epoch 42, CIFAR-10 Batch 3:  \n",
      "loss:  1.21972 valid_acc  0.3992\n",
      "Epoch 42, CIFAR-10 Batch 4:  \n",
      "loss:  1.29053 valid_acc  0.4116\n",
      "Epoch 42, CIFAR-10 Batch 5:  \n",
      "loss:  1.39969 valid_acc  0.3786\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "loss:  1.43754 valid_acc  0.4162\n",
      "Epoch 43, CIFAR-10 Batch 2:  \n",
      "loss:  1.30436 valid_acc  0.4242\n",
      "Epoch 43, CIFAR-10 Batch 3:  \n",
      "loss:  1.20019 valid_acc  0.4082\n",
      "Epoch 43, CIFAR-10 Batch 4:  \n",
      "loss:  1.30082 valid_acc  0.4084\n",
      "Epoch 43, CIFAR-10 Batch 5:  \n",
      "loss:  1.27568 valid_acc  0.4118\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "loss:  1.37664 valid_acc  0.4186\n",
      "Epoch 44, CIFAR-10 Batch 2:  \n",
      "loss:  1.29093 valid_acc  0.419\n",
      "Epoch 44, CIFAR-10 Batch 3:  \n",
      "loss:  1.18831 valid_acc  0.4064\n",
      "Epoch 44, CIFAR-10 Batch 4:  \n",
      "loss:  1.2601 valid_acc  0.4174\n",
      "Epoch 44, CIFAR-10 Batch 5:  \n",
      "loss:  1.26632 valid_acc  0.4078\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "loss:  1.36996 valid_acc  0.424\n",
      "Epoch 45, CIFAR-10 Batch 2:  \n",
      "loss:  1.31163 valid_acc  0.416\n",
      "Epoch 45, CIFAR-10 Batch 3:  \n",
      "loss:  1.18029 valid_acc  0.415\n",
      "Epoch 45, CIFAR-10 Batch 4:  \n",
      "loss:  1.18994 valid_acc  0.428\n",
      "Epoch 45, CIFAR-10 Batch 5:  \n",
      "loss:  1.26553 valid_acc  0.4088\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "loss:  1.37581 valid_acc  0.426\n",
      "Epoch 46, CIFAR-10 Batch 2:  \n",
      "loss:  1.28675 valid_acc  0.4272\n",
      "Epoch 46, CIFAR-10 Batch 3:  \n",
      "loss:  1.15388 valid_acc  0.4188\n",
      "Epoch 46, CIFAR-10 Batch 4:  \n",
      "loss:  1.23059 valid_acc  0.4284\n",
      "Epoch 46, CIFAR-10 Batch 5:  \n",
      "loss:  1.24644 valid_acc  0.4184\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "loss:  1.36276 valid_acc  0.4232\n",
      "Epoch 47, CIFAR-10 Batch 2:  \n",
      "loss:  1.25916 valid_acc  0.4324\n",
      "Epoch 47, CIFAR-10 Batch 3:  \n",
      "loss:  1.19963 valid_acc  0.4072\n",
      "Epoch 47, CIFAR-10 Batch 4:  \n",
      "loss:  1.22473 valid_acc  0.43\n",
      "Epoch 47, CIFAR-10 Batch 5:  \n",
      "loss:  1.2298 valid_acc  0.4252\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "loss:  1.33146 valid_acc  0.4298\n",
      "Epoch 48, CIFAR-10 Batch 2:  \n",
      "loss:  1.25524 valid_acc  0.4366\n",
      "Epoch 48, CIFAR-10 Batch 3:  \n",
      "loss:  1.15602 valid_acc  0.4206\n",
      "Epoch 48, CIFAR-10 Batch 4:  \n",
      "loss:  1.27051 valid_acc  0.4192\n",
      "Epoch 48, CIFAR-10 Batch 5:  \n",
      "loss:  1.42448 valid_acc  0.3772\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "loss:  1.40118 valid_acc  0.4158\n",
      "Epoch 49, CIFAR-10 Batch 2:  \n",
      "loss:  1.21013 valid_acc  0.4386\n",
      "Epoch 49, CIFAR-10 Batch 3:  \n",
      "loss:  1.18828 valid_acc  0.426\n",
      "Epoch 49, CIFAR-10 Batch 4:  \n",
      "loss:  1.23827 valid_acc  0.4322\n",
      "Epoch 49, CIFAR-10 Batch 5:  \n",
      "loss:  1.27211 valid_acc  0.4044\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "loss:  1.30332 valid_acc  0.4276\n",
      "Epoch 50, CIFAR-10 Batch 2:  \n",
      "loss:  1.2987 valid_acc  0.418\n",
      "Epoch 50, CIFAR-10 Batch 3:  \n",
      "loss:  1.12069 valid_acc  0.4332\n",
      "Epoch 50, CIFAR-10 Batch 4:  \n",
      "loss:  1.20872 valid_acc  0.421\n",
      "Epoch 50, CIFAR-10 Batch 5:  \n",
      "loss:  1.15029 valid_acc  0.435\n",
      "Epoch 51, CIFAR-10 Batch 1:  \n",
      "loss:  1.24995 valid_acc  0.4472\n",
      "Epoch 51, CIFAR-10 Batch 2:  \n",
      "loss:  1.25637 valid_acc  0.4372\n",
      "Epoch 51, CIFAR-10 Batch 3:  \n",
      "loss:  1.1604 valid_acc  0.427\n",
      "Epoch 51, CIFAR-10 Batch 4:  \n",
      "loss:  1.18221 valid_acc  0.4352\n",
      "Epoch 51, CIFAR-10 Batch 5:  \n",
      "loss:  1.16951 valid_acc  0.4382\n",
      "Epoch 52, CIFAR-10 Batch 1:  \n",
      "loss:  1.25769 valid_acc  0.4458\n",
      "Epoch 52, CIFAR-10 Batch 2:  \n",
      "loss:  1.32858 valid_acc  0.4054\n",
      "Epoch 52, CIFAR-10 Batch 3:  \n",
      "loss:  1.24804 valid_acc  0.3908\n",
      "Epoch 52, CIFAR-10 Batch 4:  \n",
      "loss:  1.17999 valid_acc  0.4364\n",
      "Epoch 52, CIFAR-10 Batch 5:  \n",
      "loss:  1.20472 valid_acc  0.4254\n",
      "Epoch 53, CIFAR-10 Batch 1:  \n",
      "loss:  1.22725 valid_acc  0.4458\n",
      "Epoch 53, CIFAR-10 Batch 2:  \n",
      "loss:  1.20363 valid_acc  0.4478\n",
      "Epoch 53, CIFAR-10 Batch 3:  \n",
      "loss:  1.13424 valid_acc  0.4418\n",
      "Epoch 53, CIFAR-10 Batch 4:  \n",
      "loss:  1.16165 valid_acc  0.4452\n",
      "Epoch 53, CIFAR-10 Batch 5:  \n",
      "loss:  1.20549 valid_acc  0.4216\n",
      "Epoch 54, CIFAR-10 Batch 1:  \n",
      "loss:  1.19407 valid_acc  0.453\n",
      "Epoch 54, CIFAR-10 Batch 2:  \n",
      "loss:  1.23642 valid_acc  0.4256\n",
      "Epoch 54, CIFAR-10 Batch 3:  \n",
      "loss:  1.09692 valid_acc  0.4448\n",
      "Epoch 54, CIFAR-10 Batch 4:  \n",
      "loss:  1.21656 valid_acc  0.4318\n",
      "Epoch 54, CIFAR-10 Batch 5:  \n",
      "loss:  1.14472 valid_acc  0.4478\n",
      "Epoch 55, CIFAR-10 Batch 1:  \n",
      "loss:  1.21719 valid_acc  0.4526\n",
      "Epoch 55, CIFAR-10 Batch 2:  \n",
      "loss:  1.15457 valid_acc  0.4572\n",
      "Epoch 55, CIFAR-10 Batch 3:  \n",
      "loss:  1.11352 valid_acc  0.4456\n",
      "Epoch 55, CIFAR-10 Batch 4:  \n",
      "loss:  1.16049 valid_acc  0.4408\n",
      "Epoch 55, CIFAR-10 Batch 5:  \n",
      "loss:  1.12959 valid_acc  0.4414\n",
      "Epoch 56, CIFAR-10 Batch 1:  \n",
      "loss:  1.21167 valid_acc  0.4562\n",
      "Epoch 56, CIFAR-10 Batch 2:  \n",
      "loss:  1.15474 valid_acc  0.4566\n",
      "Epoch 56, CIFAR-10 Batch 3:  \n",
      "loss:  1.11196 valid_acc  0.4428\n",
      "Epoch 56, CIFAR-10 Batch 4:  \n",
      "loss:  1.14215 valid_acc  0.4462\n",
      "Epoch 56, CIFAR-10 Batch 5:  \n",
      "loss:  1.11506 valid_acc  0.4422\n",
      "Epoch 57, CIFAR-10 Batch 1:  \n",
      "loss:  1.20613 valid_acc  0.457\n",
      "Epoch 57, CIFAR-10 Batch 2:  \n",
      "loss:  1.17438 valid_acc  0.4484\n",
      "Epoch 57, CIFAR-10 Batch 3:  \n",
      "loss:  1.18061 valid_acc  0.4372\n",
      "Epoch 57, CIFAR-10 Batch 4:  \n",
      "loss:  1.20995 valid_acc  0.438\n",
      "Epoch 57, CIFAR-10 Batch 5:  \n",
      "loss:  1.05298 valid_acc  0.4512\n",
      "Epoch 58, CIFAR-10 Batch 1:  \n",
      "loss:  1.18464 valid_acc  0.4348\n",
      "Epoch 58, CIFAR-10 Batch 2:  \n",
      "loss:  1.20181 valid_acc  0.4464\n",
      "Epoch 58, CIFAR-10 Batch 3:  \n",
      "loss:  1.15258 valid_acc  0.4346\n",
      "Epoch 58, CIFAR-10 Batch 4:  \n",
      "loss:  1.11469 valid_acc  0.4514\n",
      "Epoch 58, CIFAR-10 Batch 5:  \n",
      "loss:  1.02677 valid_acc  0.4542\n",
      "Epoch 59, CIFAR-10 Batch 1:  \n",
      "loss:  1.16386 valid_acc  0.4598\n",
      "Epoch 59, CIFAR-10 Batch 2:  \n",
      "loss:  1.132 valid_acc  0.4484\n",
      "Epoch 59, CIFAR-10 Batch 3:  \n",
      "loss:  1.1325 valid_acc  0.4256\n",
      "Epoch 59, CIFAR-10 Batch 4:  \n",
      "loss:  1.09149 valid_acc  0.4502\n",
      "Epoch 59, CIFAR-10 Batch 5:  \n",
      "loss:  1.05231 valid_acc  0.4568\n",
      "Epoch 60, CIFAR-10 Batch 1:  \n",
      "loss:  1.12434 valid_acc  0.468\n",
      "Epoch 60, CIFAR-10 Batch 2:  \n",
      "loss:  1.19588 valid_acc  0.437\n",
      "Epoch 60, CIFAR-10 Batch 3:  \n",
      "loss:  1.10106 valid_acc  0.45\n",
      "Epoch 60, CIFAR-10 Batch 4:  \n",
      "loss:  1.07911 valid_acc  0.4554\n",
      "Epoch 60, CIFAR-10 Batch 5:  \n",
      "loss:  1.03991 valid_acc  0.455\n",
      "Epoch 61, CIFAR-10 Batch 1:  \n",
      "loss:  1.11194 valid_acc  0.466\n",
      "Epoch 61, CIFAR-10 Batch 2:  \n",
      "loss:  1.28109 valid_acc  0.4306\n",
      "Epoch 61, CIFAR-10 Batch 3:  \n",
      "loss:  1.14448 valid_acc  0.4414\n",
      "Epoch 61, CIFAR-10 Batch 4:  \n",
      "loss:  1.09371 valid_acc  0.4488\n",
      "Epoch 61, CIFAR-10 Batch 5:  \n",
      "loss:  1.06937 valid_acc  0.4562\n",
      "Epoch 62, CIFAR-10 Batch 1:  \n",
      "loss:  1.0717 valid_acc  0.4594\n",
      "Epoch 62, CIFAR-10 Batch 2:  \n",
      "loss:  1.15022 valid_acc  0.4484\n",
      "Epoch 62, CIFAR-10 Batch 3:  \n",
      "loss:  1.07647 valid_acc  0.448\n",
      "Epoch 62, CIFAR-10 Batch 4:  \n",
      "loss:  1.04401 valid_acc  0.461\n",
      "Epoch 62, CIFAR-10 Batch 5:  \n",
      "loss:  1.06987 valid_acc  0.4542\n",
      "Epoch 63, CIFAR-10 Batch 1:  \n",
      "loss:  1.04975 valid_acc  0.4644\n",
      "Epoch 63, CIFAR-10 Batch 2:  \n",
      "loss:  1.07205 valid_acc  0.4682\n",
      "Epoch 63, CIFAR-10 Batch 3:  \n",
      "loss:  1.06159 valid_acc  0.4654\n",
      "Epoch 63, CIFAR-10 Batch 4:  \n",
      "loss:  1.08984 valid_acc  0.4618\n",
      "Epoch 63, CIFAR-10 Batch 5:  \n",
      "loss:  1.13011 valid_acc  0.4394\n",
      "Epoch 64, CIFAR-10 Batch 1:  \n",
      "loss:  1.05383 valid_acc  0.4614\n",
      "Epoch 64, CIFAR-10 Batch 2:  \n",
      "loss:  1.12733 valid_acc  0.4338\n",
      "Epoch 64, CIFAR-10 Batch 3:  \n",
      "loss:  1.07836 valid_acc  0.4492\n",
      "Epoch 64, CIFAR-10 Batch 4:  \n",
      "loss:  1.08407 valid_acc  0.4582\n",
      "Epoch 64, CIFAR-10 Batch 5:  \n",
      "loss:  0.998252 valid_acc  0.4586\n",
      "Epoch 65, CIFAR-10 Batch 1:  \n",
      "loss:  1.04147 valid_acc  0.4534\n",
      "Epoch 65, CIFAR-10 Batch 2:  \n",
      "loss:  1.06601 valid_acc  0.4658\n",
      "Epoch 65, CIFAR-10 Batch 3:  \n",
      "loss:  1.04718 valid_acc  0.4682\n",
      "Epoch 65, CIFAR-10 Batch 4:  \n",
      "loss:  1.01204 valid_acc  0.4658\n",
      "Epoch 65, CIFAR-10 Batch 5:  \n",
      "loss:  0.99077 valid_acc  0.4646\n",
      "Epoch 66, CIFAR-10 Batch 1:  \n",
      "loss:  1.05864 valid_acc  0.4648\n",
      "Epoch 66, CIFAR-10 Batch 2:  \n",
      "loss:  1.08519 valid_acc  0.4618\n",
      "Epoch 66, CIFAR-10 Batch 3:  \n",
      "loss:  1.07213 valid_acc  0.447\n",
      "Epoch 66, CIFAR-10 Batch 4:  \n",
      "loss:  1.03516 valid_acc  0.4696\n",
      "Epoch 66, CIFAR-10 Batch 5:  \n",
      "loss:  0.960087 valid_acc  0.468\n",
      "Epoch 67, CIFAR-10 Batch 1:  \n",
      "loss:  1.0214 valid_acc  0.454\n",
      "Epoch 67, CIFAR-10 Batch 2:  \n",
      "loss:  1.03597 valid_acc  0.4466\n",
      "Epoch 67, CIFAR-10 Batch 3:  \n",
      "loss:  1.03071 valid_acc  0.4616\n",
      "Epoch 67, CIFAR-10 Batch 4:  \n",
      "loss:  0.985248 valid_acc  0.4654\n",
      "Epoch 67, CIFAR-10 Batch 5:  \n",
      "loss:  1.02208 valid_acc  0.4606\n",
      "Epoch 68, CIFAR-10 Batch 1:  \n",
      "loss:  1.02933 valid_acc  0.4826\n",
      "Epoch 68, CIFAR-10 Batch 2:  \n",
      "loss:  1.04521 valid_acc  0.462\n",
      "Epoch 68, CIFAR-10 Batch 3:  \n",
      "loss:  1.01441 valid_acc  0.4476\n",
      "Epoch 68, CIFAR-10 Batch 4:  \n",
      "loss:  0.974993 valid_acc  0.4774\n",
      "Epoch 68, CIFAR-10 Batch 5:  \n",
      "loss:  0.997508 valid_acc  0.454\n",
      "Epoch 69, CIFAR-10 Batch 1:  \n",
      "loss:  1.0044 valid_acc  0.4802\n",
      "Epoch 69, CIFAR-10 Batch 2:  \n",
      "loss:  1.03184 valid_acc  0.4782\n",
      "Epoch 69, CIFAR-10 Batch 3:  \n",
      "loss:  0.977701 valid_acc  0.473\n",
      "Epoch 69, CIFAR-10 Batch 4:  \n",
      "loss:  1.01628 valid_acc  0.4666\n",
      "Epoch 69, CIFAR-10 Batch 5:  \n",
      "loss:  0.973476 valid_acc  0.466\n",
      "Epoch 70, CIFAR-10 Batch 1:  \n",
      "loss:  1.03912 valid_acc  0.4734\n",
      "Epoch 70, CIFAR-10 Batch 2:  \n",
      "loss:  1.03919 valid_acc  0.4718\n",
      "Epoch 70, CIFAR-10 Batch 3:  \n",
      "loss:  1.03726 valid_acc  0.4454\n",
      "Epoch 70, CIFAR-10 Batch 4:  \n",
      "loss:  0.965024 valid_acc  0.4644\n",
      "Epoch 70, CIFAR-10 Batch 5:  \n",
      "loss:  0.918874 valid_acc  0.463\n",
      "Epoch 71, CIFAR-10 Batch 1:  \n",
      "loss:  1.02541 valid_acc  0.481\n",
      "Epoch 71, CIFAR-10 Batch 2:  \n",
      "loss:  1.07975 valid_acc  0.4346\n",
      "Epoch 71, CIFAR-10 Batch 3:  \n",
      "loss:  0.974426 valid_acc  0.4684\n",
      "Epoch 71, CIFAR-10 Batch 4:  \n",
      "loss:  0.962666 valid_acc  0.4828\n",
      "Epoch 71, CIFAR-10 Batch 5:  \n",
      "loss:  0.940995 valid_acc  0.466\n",
      "Epoch 72, CIFAR-10 Batch 1:  \n",
      "loss:  1.00272 valid_acc  0.4822\n",
      "Epoch 72, CIFAR-10 Batch 2:  \n",
      "loss:  1.02768 valid_acc  0.4562\n",
      "Epoch 72, CIFAR-10 Batch 3:  \n",
      "loss:  0.996326 valid_acc  0.4456\n",
      "Epoch 72, CIFAR-10 Batch 4:  \n",
      "loss:  0.989973 valid_acc  0.4596\n",
      "Epoch 72, CIFAR-10 Batch 5:  \n",
      "loss:  0.922052 valid_acc  0.4792\n",
      "Epoch 73, CIFAR-10 Batch 1:  \n",
      "loss:  0.95577 valid_acc  0.4856\n",
      "Epoch 73, CIFAR-10 Batch 2:  \n",
      "loss:  0.983224 valid_acc  0.4784\n",
      "Epoch 73, CIFAR-10 Batch 3:  \n",
      "loss:  1.03154 valid_acc  0.4276\n",
      "Epoch 73, CIFAR-10 Batch 4:  \n",
      "loss:  0.94526 valid_acc  0.4732\n",
      "Epoch 73, CIFAR-10 Batch 5:  \n",
      "loss:  1.01567 valid_acc  0.4436\n",
      "Epoch 74, CIFAR-10 Batch 1:  \n",
      "loss:  0.993851 valid_acc  0.4838\n",
      "Epoch 74, CIFAR-10 Batch 2:  \n",
      "loss:  0.981205 valid_acc  0.4802\n",
      "Epoch 74, CIFAR-10 Batch 3:  \n",
      "loss:  0.967258 valid_acc  0.4544\n",
      "Epoch 74, CIFAR-10 Batch 4:  \n",
      "loss:  0.943352 valid_acc  0.48\n",
      "Epoch 74, CIFAR-10 Batch 5:  \n",
      "loss:  0.929024 valid_acc  0.4756\n",
      "Epoch 75, CIFAR-10 Batch 1:  \n",
      "loss:  0.935315 valid_acc  0.478\n",
      "Epoch 75, CIFAR-10 Batch 2:  \n",
      "loss:  1.02285 valid_acc  0.4516\n",
      "Epoch 75, CIFAR-10 Batch 3:  \n",
      "loss:  0.891028 valid_acc  0.4714\n",
      "Epoch 75, CIFAR-10 Batch 4:  \n",
      "loss:  0.912534 valid_acc  0.483\n",
      "Epoch 75, CIFAR-10 Batch 5:  \n",
      "loss:  0.875088 valid_acc  0.4764\n",
      "Epoch 76, CIFAR-10 Batch 1:  \n",
      "loss:  1.05071 valid_acc  0.4738\n",
      "Epoch 76, CIFAR-10 Batch 2:  \n",
      "loss:  0.957679 valid_acc  0.4766\n",
      "Epoch 76, CIFAR-10 Batch 3:  \n",
      "loss:  0.911945 valid_acc  0.4726\n",
      "Epoch 76, CIFAR-10 Batch 4:  \n",
      "loss:  0.88936 valid_acc  0.465\n",
      "Epoch 76, CIFAR-10 Batch 5:  \n",
      "loss:  0.880828 valid_acc  0.4832\n",
      "Epoch 77, CIFAR-10 Batch 1:  \n",
      "loss:  0.936828 valid_acc  0.4884\n",
      "Epoch 77, CIFAR-10 Batch 2:  \n",
      "loss:  0.988698 valid_acc  0.4682\n",
      "Epoch 77, CIFAR-10 Batch 3:  \n",
      "loss:  0.894639 valid_acc  0.4744\n",
      "Epoch 77, CIFAR-10 Batch 4:  \n",
      "loss:  0.917591 valid_acc  0.487\n",
      "Epoch 77, CIFAR-10 Batch 5:  \n",
      "loss:  0.884443 valid_acc  0.4862\n",
      "Epoch 78, CIFAR-10 Batch 1:  \n",
      "loss:  0.942016 valid_acc  0.4884\n",
      "Epoch 78, CIFAR-10 Batch 2:  \n",
      "loss:  0.980092 valid_acc  0.456\n",
      "Epoch 78, CIFAR-10 Batch 3:  \n",
      "loss:  0.882491 valid_acc  0.4744\n",
      "Epoch 78, CIFAR-10 Batch 4:  \n",
      "loss:  0.928321 valid_acc  0.4654\n",
      "Epoch 78, CIFAR-10 Batch 5:  \n",
      "loss:  0.848855 valid_acc  0.4824\n",
      "Epoch 79, CIFAR-10 Batch 1:  \n",
      "loss:  0.910201 valid_acc  0.494\n",
      "Epoch 79, CIFAR-10 Batch 2:  \n",
      "loss:  0.943076 valid_acc  0.4834\n",
      "Epoch 79, CIFAR-10 Batch 3:  \n",
      "loss:  0.859265 valid_acc  0.4828\n",
      "Epoch 79, CIFAR-10 Batch 4:  \n",
      "loss:  0.892048 valid_acc  0.497\n",
      "Epoch 79, CIFAR-10 Batch 5:  \n",
      "loss:  0.923669 valid_acc  0.4662\n",
      "Epoch 80, CIFAR-10 Batch 1:  \n",
      "loss:  0.927847 valid_acc  0.4886\n",
      "Epoch 80, CIFAR-10 Batch 2:  \n",
      "loss:  0.949843 valid_acc  0.4682\n",
      "Epoch 80, CIFAR-10 Batch 3:  \n",
      "loss:  0.89537 valid_acc  0.46\n",
      "Epoch 80, CIFAR-10 Batch 4:  \n",
      "loss:  0.919935 valid_acc  0.4584\n",
      "Epoch 80, CIFAR-10 Batch 5:  \n",
      "loss:  0.878579 valid_acc  0.4684\n",
      "Epoch 81, CIFAR-10 Batch 1:  \n",
      "loss:  0.907171 valid_acc  0.4872\n",
      "Epoch 81, CIFAR-10 Batch 2:  \n",
      "loss:  0.963976 valid_acc  0.4664\n",
      "Epoch 81, CIFAR-10 Batch 3:  \n",
      "loss:  0.88307 valid_acc  0.4668\n",
      "Epoch 81, CIFAR-10 Batch 4:  \n",
      "loss:  0.82958 valid_acc  0.4828\n",
      "Epoch 81, CIFAR-10 Batch 5:  \n",
      "loss:  0.820039 valid_acc  0.4928\n",
      "Epoch 82, CIFAR-10 Batch 1:  \n",
      "loss:  0.872689 valid_acc  0.4908\n",
      "Epoch 82, CIFAR-10 Batch 2:  \n",
      "loss:  0.948206 valid_acc  0.4642\n",
      "Epoch 82, CIFAR-10 Batch 3:  \n",
      "loss:  0.836747 valid_acc  0.475\n",
      "Epoch 82, CIFAR-10 Batch 4:  \n",
      "loss:  0.859398 valid_acc  0.4472\n",
      "Epoch 82, CIFAR-10 Batch 5:  \n",
      "loss:  0.809243 valid_acc  0.4824\n",
      "Epoch 83, CIFAR-10 Batch 1:  \n",
      "loss:  0.974723 valid_acc  0.4716\n",
      "Epoch 83, CIFAR-10 Batch 2:  \n",
      "loss:  0.925415 valid_acc  0.4634\n",
      "Epoch 83, CIFAR-10 Batch 3:  \n",
      "loss:  0.829337 valid_acc  0.4772\n",
      "Epoch 83, CIFAR-10 Batch 4:  \n",
      "loss:  0.819407 valid_acc  0.4768\n",
      "Epoch 83, CIFAR-10 Batch 5:  \n",
      "loss:  0.821547 valid_acc  0.4924\n",
      "Epoch 84, CIFAR-10 Batch 1:  \n",
      "loss:  0.939227 valid_acc  0.4872\n",
      "Epoch 84, CIFAR-10 Batch 2:  \n",
      "loss:  0.922699 valid_acc  0.4822\n",
      "Epoch 84, CIFAR-10 Batch 3:  \n",
      "loss:  0.813237 valid_acc  0.4818\n",
      "Epoch 84, CIFAR-10 Batch 4:  \n",
      "loss:  0.828053 valid_acc  0.4832\n",
      "Epoch 84, CIFAR-10 Batch 5:  \n",
      "loss:  0.794659 valid_acc  0.4886\n",
      "Epoch 85, CIFAR-10 Batch 1:  \n",
      "loss:  0.924139 valid_acc  0.4828\n",
      "Epoch 85, CIFAR-10 Batch 2:  \n",
      "loss:  0.894006 valid_acc  0.4742\n",
      "Epoch 85, CIFAR-10 Batch 3:  \n",
      "loss:  0.832129 valid_acc  0.467\n",
      "Epoch 85, CIFAR-10 Batch 4:  \n",
      "loss:  0.809294 valid_acc  0.4584\n",
      "Epoch 85, CIFAR-10 Batch 5:  \n",
      "loss:  0.808468 valid_acc  0.4826\n",
      "Epoch 86, CIFAR-10 Batch 1:  \n",
      "loss:  0.859402 valid_acc  0.4834\n",
      "Epoch 86, CIFAR-10 Batch 2:  \n",
      "loss:  0.904746 valid_acc  0.479\n",
      "Epoch 86, CIFAR-10 Batch 3:  \n",
      "loss:  0.814202 valid_acc  0.4942\n",
      "Epoch 86, CIFAR-10 Batch 4:  \n",
      "loss:  0.783161 valid_acc  0.4972\n",
      "Epoch 86, CIFAR-10 Batch 5:  \n",
      "loss:  0.791403 valid_acc  0.4894\n",
      "Epoch 87, CIFAR-10 Batch 1:  \n",
      "loss:  0.834888 valid_acc  0.494\n",
      "Epoch 87, CIFAR-10 Batch 2:  \n",
      "loss:  0.897086 valid_acc  0.474\n",
      "Epoch 87, CIFAR-10 Batch 3:  \n",
      "loss:  0.772868 valid_acc  0.4922\n",
      "Epoch 87, CIFAR-10 Batch 4:  \n",
      "loss:  0.765764 valid_acc  0.4938\n",
      "Epoch 87, CIFAR-10 Batch 5:  \n",
      "loss:  0.821635 valid_acc  0.4932\n",
      "Epoch 88, CIFAR-10 Batch 1:  \n",
      "loss:  0.851265 valid_acc  0.4892\n",
      "Epoch 88, CIFAR-10 Batch 2:  \n",
      "loss:  0.882849 valid_acc  0.474\n",
      "Epoch 88, CIFAR-10 Batch 3:  \n",
      "loss:  0.787245 valid_acc  0.4856\n",
      "Epoch 88, CIFAR-10 Batch 4:  \n",
      "loss:  0.768888 valid_acc  0.4716\n",
      "Epoch 88, CIFAR-10 Batch 5:  \n",
      "loss:  0.870653 valid_acc  0.462\n",
      "Epoch 89, CIFAR-10 Batch 1:  \n",
      "loss:  0.862586 valid_acc  0.487\n",
      "Epoch 89, CIFAR-10 Batch 2:  \n",
      "loss:  0.899827 valid_acc  0.463\n",
      "Epoch 89, CIFAR-10 Batch 3:  \n",
      "loss:  0.782377 valid_acc  0.4954\n",
      "Epoch 89, CIFAR-10 Batch 4:  \n",
      "loss:  0.738671 valid_acc  0.4912\n",
      "Epoch 89, CIFAR-10 Batch 5:  \n",
      "loss:  0.78077 valid_acc  0.4938\n",
      "Epoch 90, CIFAR-10 Batch 1:  \n",
      "loss:  0.872908 valid_acc  0.4932\n",
      "Epoch 90, CIFAR-10 Batch 2:  \n",
      "loss:  0.898377 valid_acc  0.4624\n",
      "Epoch 90, CIFAR-10 Batch 3:  \n",
      "loss:  0.770824 valid_acc  0.4958\n",
      "Epoch 90, CIFAR-10 Batch 4:  \n",
      "loss:  0.750435 valid_acc  0.4874\n",
      "Epoch 90, CIFAR-10 Batch 5:  \n",
      "loss:  0.756972 valid_acc  0.4976\n",
      "Epoch 91, CIFAR-10 Batch 1:  \n",
      "loss:  0.813634 valid_acc  0.4938\n",
      "Epoch 91, CIFAR-10 Batch 2:  \n",
      "loss:  0.917632 valid_acc  0.4864\n",
      "Epoch 91, CIFAR-10 Batch 3:  \n",
      "loss:  0.749547 valid_acc  0.4928\n",
      "Epoch 91, CIFAR-10 Batch 4:  \n",
      "loss:  0.743342 valid_acc  0.4974\n",
      "Epoch 91, CIFAR-10 Batch 5:  \n",
      "loss:  0.783157 valid_acc  0.499\n",
      "Epoch 92, CIFAR-10 Batch 1:  \n",
      "loss:  0.802967 valid_acc  0.4966\n",
      "Epoch 92, CIFAR-10 Batch 2:  \n",
      "loss:  0.886151 valid_acc  0.4824\n",
      "Epoch 92, CIFAR-10 Batch 3:  \n",
      "loss:  0.931775 valid_acc  0.4108\n",
      "Epoch 92, CIFAR-10 Batch 4:  \n",
      "loss:  0.752218 valid_acc  0.4706\n",
      "Epoch 92, CIFAR-10 Batch 5:  \n",
      "loss:  0.733731 valid_acc  0.4974\n",
      "Epoch 93, CIFAR-10 Batch 1:  \n",
      "loss:  0.838488 valid_acc  0.501\n",
      "Epoch 93, CIFAR-10 Batch 2:  \n",
      "loss:  0.859937 valid_acc  0.4842\n",
      "Epoch 93, CIFAR-10 Batch 3:  \n",
      "loss:  0.778149 valid_acc  0.4706\n",
      "Epoch 93, CIFAR-10 Batch 4:  \n",
      "loss:  0.743871 valid_acc  0.4832\n",
      "Epoch 93, CIFAR-10 Batch 5:  \n",
      "loss:  0.767626 valid_acc  0.494\n",
      "Epoch 94, CIFAR-10 Batch 1:  \n",
      "loss:  0.815561 valid_acc  0.4914\n",
      "Epoch 94, CIFAR-10 Batch 2:  \n",
      "loss:  0.865553 valid_acc  0.4602\n",
      "Epoch 94, CIFAR-10 Batch 3:  \n",
      "loss:  0.729168 valid_acc  0.4836\n",
      "Epoch 94, CIFAR-10 Batch 4:  \n",
      "loss:  0.726789 valid_acc  0.4908\n",
      "Epoch 94, CIFAR-10 Batch 5:  \n",
      "loss:  0.736341 valid_acc  0.4984\n",
      "Epoch 95, CIFAR-10 Batch 1:  \n",
      "loss:  0.800914 valid_acc  0.4894\n",
      "Epoch 95, CIFAR-10 Batch 2:  \n",
      "loss:  0.899096 valid_acc  0.461\n",
      "Epoch 95, CIFAR-10 Batch 3:  \n",
      "loss:  0.810714 valid_acc  0.4472\n",
      "Epoch 95, CIFAR-10 Batch 4:  \n",
      "loss:  0.734684 valid_acc  0.4786\n",
      "Epoch 95, CIFAR-10 Batch 5:  \n",
      "loss:  0.775454 valid_acc  0.4806\n",
      "Epoch 96, CIFAR-10 Batch 1:  \n",
      "loss:  0.840116 valid_acc  0.48\n",
      "Epoch 96, CIFAR-10 Batch 2:  \n",
      "loss:  0.801316 valid_acc  0.4876\n",
      "Epoch 96, CIFAR-10 Batch 3:  \n",
      "loss:  0.709926 valid_acc  0.4922\n",
      "Epoch 96, CIFAR-10 Batch 4:  \n",
      "loss:  0.718511 valid_acc  0.4954\n",
      "Epoch 96, CIFAR-10 Batch 5:  \n",
      "loss:  0.71494 valid_acc  0.5068\n",
      "Epoch 97, CIFAR-10 Batch 1:  \n",
      "loss:  0.769999 valid_acc  0.5\n",
      "Epoch 97, CIFAR-10 Batch 2:  \n",
      "loss:  0.817658 valid_acc  0.4934\n",
      "Epoch 97, CIFAR-10 Batch 3:  \n",
      "loss:  0.709898 valid_acc  0.478\n",
      "Epoch 97, CIFAR-10 Batch 4:  \n",
      "loss:  0.700062 valid_acc  0.495\n",
      "Epoch 97, CIFAR-10 Batch 5:  \n",
      "loss:  0.740012 valid_acc  0.4936\n",
      "Epoch 98, CIFAR-10 Batch 1:  \n",
      "loss:  0.894311 valid_acc  0.458\n",
      "Epoch 98, CIFAR-10 Batch 2:  \n",
      "loss:  0.815823 valid_acc  0.5012\n",
      "Epoch 98, CIFAR-10 Batch 3:  \n",
      "loss:  0.681325 valid_acc  0.5072\n",
      "Epoch 98, CIFAR-10 Batch 4:  \n",
      "loss:  0.694067 valid_acc  0.4836\n",
      "Epoch 98, CIFAR-10 Batch 5:  \n",
      "loss:  0.706095 valid_acc  0.502\n",
      "Epoch 99, CIFAR-10 Batch 1:  \n",
      "loss:  0.790036 valid_acc  0.4972\n",
      "Epoch 99, CIFAR-10 Batch 2:  \n",
      "loss:  0.893068 valid_acc  0.4502\n",
      "Epoch 99, CIFAR-10 Batch 3:  \n",
      "loss:  0.705378 valid_acc  0.5042\n",
      "Epoch 99, CIFAR-10 Batch 4:  \n",
      "loss:  0.68888 valid_acc  0.4864\n",
      "Epoch 99, CIFAR-10 Batch 5:  \n",
      "loss:  0.69566 valid_acc  0.4938\n",
      "Epoch 100, CIFAR-10 Batch 1:  \n",
      "loss:  0.777804 valid_acc  0.492\n",
      "Epoch 100, CIFAR-10 Batch 2:  \n",
      "loss:  0.871644 valid_acc  0.4818\n",
      "Epoch 100, CIFAR-10 Batch 3:  \n",
      "loss:  0.663256 valid_acc  0.5008\n",
      "Epoch 100, CIFAR-10 Batch 4:  \n",
      "loss:  0.708944 valid_acc  0.4822\n",
      "Epoch 100, CIFAR-10 Batch 5:  \n",
      "loss:  0.780567 valid_acc  0.4762\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.46630859375\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLCIiIiISKTgWEREREYn+P4BV0HC4XN8CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e5a709b70>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
